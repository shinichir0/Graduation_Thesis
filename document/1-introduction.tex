\chapter{はじめに}
近年、深層学習という多層に重ねたニューラルネットワークにおいて目的関数の誤差を減少させる
ことで最適化を行うモデルが様々なタスクで成果をあげている。
その中でもRNN, LSTMといった時系列データを扱うモデルが自然言語処理や音声認識といった幅広い分野に用いられている。

しかし人間の脳における大脳皮質の学習は目的関数に対して最適化するという学習をおこなっているのではないとされている。\cite{neurons}
人間の脳における学習はニューロンが発火していくことによるニューロン間をつなぐシナプスの発生によって行われる。
この学習を模したニューラルネットワークモデルとしてHierarchical Temporal Memory(HTM)が提案された。\cite{htm}

HTMの構造や学習アルゴリズムは人間の脳の大脳皮質を模したものとなっている。
HTMの構造は神経細胞を模したセルと名付けなれたノードを2次元マップ状に配置したものとなっている。
またそのセルはそれぞれ非活性化状態、予測状態、活性化状態と遷移するようになっている。
学習アルゴリズムはそのセル間の繋がりであるシナプス接続の可否を変化させるというものである。
シナプス接続の可否は各シナプスの接続値を増減させることで変化させるが、それはヘブ則によって行われる。これはあるセルの発火の後に他のセルが発火した時にその２つのセル間のシナプス接続が強化させるというものである。

HTMはシナプス接続を元にして活性化状態のセルと繋がっているセルが予測状態に遷移し、次の時刻に置いて予測状態のセルが活性化状態に遷移することに時系列データを再現しようとする。
HTMはこのシナプス接続を束ねたものとしてセグメントという機構があるが、これは神経細胞の樹状突起を模したものである。またこのセグメントは１つのセルに対して複数あるためセグメント集合となる。

またHTMの学習は深層学習でよく用いられるミニバッチ学習とは異なり、１つ１つのデータの入力に対して学習を更新するオンライン学習となっており、目的関数に対して最適化を行うのではないため教師なし学習に分類される。

他のHTMの特徴として疎な分散表現が挙げられる。マップ状になったセルの内わずかなセルのみが発火してデータを表現するため少ない計算量と幅広い表現力を持っている。

HTMは深層学習におけるニューラルネットワークに対してわずかなタスクにおいては優位性があるが、ほとんどのタスクにおいて低い精度となっており、また自然言語処理などの複雑なタスクには用いられていない。特にRNNに長期依存考慮のためのゲート機構を導入したLSTMのような高度な時系列予測が行えていない。

この原因としてHTMには長期依存考慮のための機構が加えられていないことが考えられる。特に疎な分散表現による学習が続けられていくによって発火するセルが減少していき予測情報が維持できなくなっていることによる長期依存関係の消失が伺える。

そのため本研究ではHTMのセグメント集合に対して時間軸を導入し、複数前の時刻におけるデータを表現しているセルとの繋がりも学習していくことによって疎な分散表現を維持しつつも長期依存関係も学習できることを目指す。またHTMの学習アルゴリズムを改良した研究というものは現在挙げられていない。

本研究の評価として様々な時系列データの予測タスクにおいて従来のHTMとの比較を行った。

以下、第２章でHTMの構造と学習アルゴリズムについて詳しく述べ、第３章で改良したHTMについて、第４章で評価実験、第５章で結論を述べる。
