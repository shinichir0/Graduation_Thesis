\chapter{学習・テストデータの作成}

\section{使用データセット}

提案システムにおいて学習やテストに用いる画像には，CelebAデータセット\cite{liu2015faceattributes}を使用した．このデータセットは，著名人の顔画像20万2599枚から成るデータセットで，40種類の属性ラベルが各画像に付加されている．画像生成には大量の画像が必要であり，また，属性情報が付与されているデータセットが必要であるためCelebAデータセットを使用した．
%http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html

\section{画像のリサイズ}
使用するCelebAデータセットの画像サイズは178$\times$218pixelsである．画像の特徴量を抽出するVGG-19ネットワークは入力とする画像のサイズが224$\times$224pixelsに限定されているため，CelebAデータセットの画像をリサイズする必要がある．行った処理の流れを図\ref{fig:resize}に示す．

\begin{figure}[H]
 \begin{center}
  \includegraphics[scale=0.5]{./fig/resize.eps}
  \caption{画像サイズ処理の流れ}
  \label{fig:resize}
 \end{center}
\end{figure}


\begin{description}
\item[1．正方形に切り取る.]\mbox{}\\ 
実行結果の例を図\ref{fig:crop}に示す．CelebAデータセット内の画像は顔が画像の中心にあるものが多いため，上下20pixelを切り取り，178$\times$178pixelsの画像を作成した．顔の領域を正確に切り取る方法として，顔検出を行い，その領域を切り取る事も考慮したが，顔検出を正しく行えなかった場合の対処にかかる手間や，狭く切り取ってしまう事で属性情報が失われてしまう可能性を考え，単純に上下20pixelを切り取る方法を選択した．

\begin{figure}[H]
 \begin{center}
  \includegraphics[scale=0.7]{./fig/crop.eps}
  \caption{切り取り方法の違い}
  \label{fig:crop}
 \end{center}
\end{figure}

\item[2．Cl-waifu2xを利用して解像度を失わずに拡大する.]\mbox{}\\ 
実行結果の例を図\ref{fig:waifu2x}に示す．178$\times$178pixelsの画像をそのまま224$\times$224pixelsにリサイズしてしまうと，解像度が失われてしまうため，解像度を保ったまま画像を拡大する事が出来るCl-waifu2x\cite{waifu2x}というシステムを利用した．Cl-waifu2xとは，OpenCLを用いて実装された，解像度を保ったまま2倍の大きさに画像を拡大する事が出来るシステムである．これにより，画像サイズは356$\times$356pixelsとなる．
%https://github.com/marcan/cl-waifu2x
\begin{figure}[H]
 \begin{center}
  \includegraphics[scale=0.5]{./fig/waifu2x.eps}
  \caption{waifu2xによる拡大}
  \label{fig:waifu2x}
 \end{center}
\end{figure}


\item[3．224$\times$224pixelsに縮小する．]\mbox{}\\  
実行結果の例を図\ref{fig:small}に示す．作成した356$\times$356pixelsの画像を，VGG-19ネットワークに入力できるように224$\times$224pixelsに縮小した．
\begin{figure}[H]
 \begin{center}
  \includegraphics[scale=0.2]{./fig/small.eps}
  \caption{縮小}
  \label{fig:small}
 \end{center}
\end{figure}
\end{description}

\section{属性を持つ・持たない画像組の抽出}
今回は付与する属性として、笑顔の例で入出力データの抽出方法について述べる．提案モデルを学習・テストするためには，笑顔・笑顔ではない画像の組が一定数必要となり，この画像組を用いて付与する属性特徴量を生成する．この笑顔・笑顔ではない画像の組を抽出する方法として次の5パターンを考えた．

\begin{description}
\item[1．CelebAデータセットに付属しているラベル情報を用いる方法]\mbox{}\\ 
図\ref{fig:listattr}に，CelebAデータセットに付属している”list\_attr\_celeba.txt”というテキストファイルの一部を示す.テキストファイルにラベル情報が記入されており，各属性にあてはまる場合に”1”，あてはまらない場合に”-1”が記入してある． ただし，図\ref{fig:listattr}の上段の数字は属性番号を示す．本来のテキストファイルには属性名が記述されているが，省略のため番号で表した．このテキストファイルを用いて，笑顔属性が異なり，他39属性が同じ画像の組を抽出する．抽出アルゴリズムを図\ref{fig:overlap}に示す．

\begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.4]{./fig/listattr.eps}
 		\caption{”list\_attr\_celeba.txt”の一部}
 		\label{fig:listattr}
 	\end{center}
 \end{figure}
 \begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.6]{./fig/overlap.eps}
 		\caption{ラベル情報を用いた抽出方法}
 		\label{fig:overlap}
 	\end{center}
 \end{figure}
 
この抽出方法により抽出された画像組の例を図\ref{fig:imageoverlap}に示す．
\begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.25]{./fig/imageoverlap.eps}
 		\caption{抽出した画像例}
 		\label{fig:imageoverlap}
 	\end{center}
 \end{figure}

この抽出方法では，ラベルが類似している画像が選択できる一方で，図\ref{fig:imageoverlap}の2，3の例をみると分かるように，1枚の画像に対して複数の画像が対応してしまう場合がある．

\item[2．1.で抽出した画像ペアから重複を削除する方法]\mbox{}\\ 
上で述べたように，1.の抽出方法では，1枚の画像に対して複数の画像が対応してしまう場合がある．このような場合，生成する画像が特定の画像に類似してしまうなどの問題点が発生する．そのため，1.で抽出した画像組の中からランダムに重複する画像組を削除した．抽出アルゴリズムを図\ref{fig:removeoverlap}に示す．
\begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.6]{./fig/removeoverlap.eps}
 		\caption{重複する画像組の削除方法}
 		\label{fig:removeoverlap}
 	\end{center}
 \end{figure}

\item[3．画像の類似度を用いる方法]\mbox{}\\ 
1.の方法で抽出した画像組は，ラベルが類似している画像が選択可能であるが，顔の向きや背景色などのラベル情報以外の要素が大きく異なる画像が選択されてしまうという問題点がある．そこで，画像の類似度を考慮した笑顔・笑顔ではない画像組の抽出方法を考えた．抽出アルゴリズムを図\ref{fig:cossim}に示す． まずCelebAデータセットの全ての画像を笑顔の画像群，笑顔ではない画像群に分割する．分割した笑顔の画像群1枚に対し，笑顔ではない画像群の全ての画像との類似度を計算し，類似度が1番高い画像を選択する．画像の類似度計算にはコサイン類似度を使用した．生成したい画像(笑顔画像)を$\bm{x}^t$，入力画像(笑顔ではない画像)を$\bm{x}^s$とする．コサイン類似度による画像の類似度は
\begin{equation}
  cos(\bm{x}^t, \bm{x}^s) = \frac{\bm{x}^t \cdot \bm{x}^s}{|\bm{x}^t||\bm{x}^s|}
\end{equation}
と計算できる.
画像を読み込んだRGB値の行列を1次元のベクトルに変換し，コサイン類似度の計算を行った．
\begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.6]{./fig/cossim.eps}
 		\caption{画像の類似度による抽出方法}
 		\label{fig:cossim}
 	\end{center}
 \end{figure}

この抽出方法により抽出された画像組の例を図\ref{fig:imagecossim}に示す．
\begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.25]{./fig/imagecossim.eps}
 		\caption{抽出した画像例}
 		\label{fig:imagecossim}
 	\end{center}
 \end{figure}

ただし，この抽出方法では重複する画像が存在する可能性があるという問題点がある．また，背景や顔の向きなどを考慮した画像ペアを抽出できる一方で，図\ref{fig:imagecossim}の3のように，笑顔以外の属性の異なる画像ペアを選択してしまうという問題点が存在する．しかし，笑顔属性に含まれる画像の数だけ画像組を抽出できるため，他の抽出方法に比べて大規模な画像組を作成できる．

\item[4．1.で抽出した画像ペアから画像の類似度を利用して重複を削除する方法]\mbox{}\\ 
以上のパターンを考慮し，1.で抽出した画像ペアから重複を削除する際に，単純に削除するのではなく，コサイン類似度の一番高い組を選択する事で重複を削除した．これにより，笑顔以外の属性が等しい画像ペアが選択でき，また，背景や顔の向きなどを考慮した画像ペアを選択する事ができる．抽出アルゴリズムを図\ref{fig:labelcossim}に示す．
\begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.3]{./fig/labelcossim.eps}
 		\caption{画像の類似度による重複する画像組の削除方法}
 		\label{fig:labelcossim}
 	\end{center}
\end{figure}

\item[5．CNNで抽出した特徴量による画像の類似度を用いる方法]\mbox{}\\
画像の特徴量を抽出するCNNとして，本研究ではVGG-19モデル\cite{vgg}を使用する．詳細は次章で説明する．これにより得られた画像特徴量は4096次元のベクトルで表される．3．で述べたコサイン類似度による属性を持つ・持たない組の抽出には，画像のRGB値を用いた．しかしこの場合，画像組にはラベルの異なる画像も含まれてしまう場合も少なくない．そこで，分類タスクに用いられる事が多いCNNを用いて抽出された画像特徴量を用いる事で，ラベルの異なる画像組の抽出の低減を試みた．抽出アルゴリズムは図\ref{fig:cossim}と同じであるため割愛する．これにより抽出した画像組の例を図\ref{fig:imagesim4096}に示す．

\begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.25]{./fig/imagesim4096.eps}
 		\caption{抽出した画像例}
 		\label{fig:imagesim4096}
 	\end{center}
 \end{figure}

\end{description}

\section{入出力データの作成}

\subsection{入力データ}
提案システムでは，前処理を行った画像から画像特徴量を取得し，これを入力とした．この画像特徴量の抽出にはImageNet Challenge\cite{imagenet}で高精度を残しているCNNの一種である，VGG-19モデルを使用した．図\ref{fig:vgg}にVGG-19モデルの構造を示す．19層からなるCNNの一種であり，畳込み処理とプーリング処理を行った後に，全結合層を結合させたモデルとなっている．本研究では，学習済みのVGG-19モデルを使用して，前処理を行った画像を入力し，図\ref{fig:vgg}のfc7層の4096次元の画像特徴量を取得した．画像の特徴量を取得する際には，追加の学習は行わない．笑顔画像を生成する際には，笑顔ではない画像の特徴量を抽出し，入力する．ここで，最後の1000次元の特徴量を用いなかった理由は以下の通りである．使用したVGG-19ネットワークはILSVRCという1000クラス分類における精度を競うコンテストのために使用されたネットワークであり，最後の出力の1000次元ベクトルは，1000クラスに相当するからである．本研究では画像の特徴量を表す値を得るのが目的であるため、最後の1000次元を用いずに，その分類に用いる，最後より1つ前の層の4096次元の値を使用した． 
\begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.32]{./fig/vgg.eps}
 		\caption{VGG-19モデルの構造}
 		\label{fig:vgg}
 	\end{center}
\end{figure}


\subsection{出力データ}
提案システムにおける出力は，生成画像である．生成する画像のサイズは64$\times$64pixelsとした．提案モデルを学習する際には，CelebAデータセットの笑顔画像を教師画像とし，生成画像が笑顔画像と類似するように学習を行う．

\subsection{作成したデータセット}
\subsubsection{笑顔属性の場合}
第2.3章で述べた属性を持つ画像・属性を持たない画像組の抽出方法を元に，作成した笑顔属性データセットを以下の表\ref{tab:dataset}に示す.	 抽出した属性を持つ画像・属性を持たない画像組を学習用の画像とテスト用の画像に分割し，学習・テストに用いた．
\begin{table}[H]
  \begin{center}
    \caption{作成した笑顔データセット一覧}
    \begin{tabular}{|c|c|c|c|} \hline
      抽出方法 & 名前 & 学習用枚数 & テスト用枚数 \\ \hline
      2 & 重複なしラベルデータセット & 10,005 & 3,000 \\ \hline
      3 & RGB値コサイン類似度データセット & 50,000 & 4,222 \\ \hline
      4 & 重複なしコサイン類似度データセット & 10,005 & 3,000 \\ \hline
      5 & 画像特徴量コサイン類似度データセット & 50,000 & 5,000 \\ \hline
    \end{tabular}
    \label{tab:dataset}
  \end{center}
\end{table}

\subsubsection{男性属性の場合}
表\ref{tab:dataset2}に，作成した男性属性データセットを示す．抽出した属性を持つ画像・属性を持たない画像組を学習用の画像とテスト用の画像に分割し，学習・テストに用いた．
\newpage
\begin{table}[H]
  \begin{center}
    \caption{作成した男性データセット一覧}
    \begin{tabular}{|c|c|c|c|} \hline
      抽出方法 & 名前 & 学習用枚数 & テスト用枚数 \\ \hline
      2 & 重複なしラベルデータセット & 6,000 & 1,619 \\ \hline
      3 & RGB値コサイン類似度データセット & 50,000 & 2,850 \\ \hline
      4 & 重複なしコサイン類似度データセット & 6,000 & 1,619 \\ \hline
      5 & 画像特徴量コサイン類似度データセット & 50,000 & 5,000 \\ \hline
    \end{tabular}
    \label{tab:dataset2}
  \end{center}
\end{table}

\section{属性特徴量の作成}
属性特徴量の作成には，入力データの作成と同じくVGG-19モデルにより抽出した画像特徴量を使用した．その処理の流れを図\ref{fig:attrfeature}に示す．

\begin{figure}[H]
 	\begin{center}
 		\includegraphics[scale=0.7]{./fig/attrfeature.eps}
 		\caption{属性特徴量作成の流れ}
 		\label{fig:attrfeature}
 	\end{center}
\end{figure}

学習に用いる笑顔画像群$S^t = \{\bm{x}^t_{1}，...，\bm{x}^t_{n}\}$，笑顔ではない画像群$S^s = \{\bm{x}^s_{1}，...，\bm{x}^s_{n}\}$をそれぞれVGG-19モデルに入力し，特徴量を抽出する．抽出した特徴量を$F^t = \{\bm{f}^t_{1}，...，\bm{f}^t_{n}\}$，$F^s = \{\bm{f}^s_{1}，...，\bm{f}^s_{n}\}$とする．それぞれ抽出した特徴量の差分をとり，画像ペア数で平均をとる事で，以下のように属性特徴量$\bm{A}$を作成した．

\begin{equation}
  \bm{A} = \frac{\sum^{n}_{i=1}(\bm{f}^t_{i} - \bm{f}^s_{i})}{n}
\end{equation}

提案システムに，ある画像を入力する際に，属性特徴量を足す．この時に，属性特徴量に重み$\alpha$をかけ，属性特徴量の割合が最適になるように調整を行った．提案システムの入力$\bm{i}$は以下のように表すことができる．

\begin{equation}
  \bm{i} = \bm{x}^s + \alpha\bm{A}
\end{equation}
